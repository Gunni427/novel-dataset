{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapes the novelupdates webpage, http://www.novelupdates.com/\n",
    "for novel information and cleans it.\n",
    "Finally saves the dataset as a csv file.\n",
    "\n",
    "Didn't find any easy way to get all the novel ids, hence, the novels listing is first used to get all ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "novels_page = \"http://www.novelupdates.com/novelslisting/?st=1&pg=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum number of novel pages from the listings\n",
    "\n",
    "def get_novel_list_max_pages(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    dig_pag = soup.find('div', attrs={'class':'digg_pagination'})\n",
    "    page_links = dig_pag.find_all('a')\n",
    "    last_page_link = str(page_links[2]) # The last page is the 3rd\n",
    "    num = re.search('pg=\\d+', last_page_link).group()[3:]\n",
    "    return int(num)\n",
    "\n",
    "page = requests.get(novels_page + '1')\n",
    "novels_max_pages = get_novel_list_max_pages(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           0\n",
      "0      1173\n",
      "1      1175\n",
      "2      1177\n",
      "3     13038\n",
      "4      1171\n",
      "5      2042\n",
      "6      6612\n",
      "7     11133\n",
      "8      9343\n",
      "9      8233\n",
      "10     7959\n",
      "11     2696\n",
      "12    13155\n",
      "13     2742\n",
      "14     7145\n",
      "15     5400\n",
      "16     9314\n",
      "17    10927\n",
      "18     1179\n",
      "19    12408\n",
      "20    13080\n",
      "21     1069\n",
      "22    13197\n",
      "23    12584\n",
      "24     1181\n",
      "25     1183\n",
      "26     3992\n",
      "27     1185\n",
      "28     8674\n",
      "29    10925\n",
      "...     ...\n",
      "2952   8640\n",
      "2953  10129\n",
      "2954    567\n",
      "2955   5306\n",
      "2956   1916\n",
      "2957   4230\n",
      "2958   6391\n",
      "2959  12628\n",
      "2960   2029\n",
      "2961   5992\n",
      "2962    364\n",
      "2963   5402\n",
      "2964   2031\n",
      "2965   5585\n",
      "2966   2033\n",
      "2967   2035\n",
      "2968   2037\n",
      "2969    177\n",
      "2970   2039\n",
      "2971   2916\n",
      "2972  11539\n",
      "2973   8591\n",
      "2974   6871\n",
      "2975   5205\n",
      "2976   7143\n",
      "2977   8059\n",
      "2978   9480\n",
      "2979  10040\n",
      "2980   5519\n",
      "2981  11601\n",
      "\n",
      "[2982 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Get all novel ids from the novels listing\n",
    "\n",
    "# Overwrite for testing\n",
    "# novels_max_pages = 3 \n",
    "\n",
    "def get_novel_ids(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find('table', attrs={'id':'myTable'})\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    \n",
    "    novel_ids = []\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')[-1]\n",
    "        novel_id = col.a['id'][3:]\n",
    "        novel_ids.append(novel_id)\n",
    "    return novel_ids\n",
    "\n",
    "all_novel_ids = []\n",
    "for i in range(1,novels_max_pages+1):\n",
    "    page = requests.get(novels_page + str(i))\n",
    "    novel_ids = get_novel_ids(page)\n",
    "    all_novel_ids.extend(novel_ids)\n",
    "    time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(all_novel_ids)\n",
    "print(df.head)\n",
    "df.to_csv(\"novel_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
