{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel dataset web scraper\n",
    "\n",
    "Gathers novel information from novelupdates, i.e. http://www.novelupdates.com/.  \n",
    "The data is then cleaned and arranged into a dataset.  \n",
    "The dataset is finally saved as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Display all columns when showing dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "novel_list_page = \"http://www.novelupdates.com/novelslisting/?st=1&pg=\"\n",
    "novel_page = \"http://www.novelupdates.com/?p=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There do not seem to be an easy way to get all novel ids. These ids do not seem to be necessarily be strictly consecutive or increasing. Hence a brute force method is used to gather the ids of all current novels.\n",
    "\n",
    "The ids are gathered from a list of all the novels. \n",
    "The list contains mulitple pages/tabs with each page consisting of 25 novels.\n",
    "First the number of novel pages is retrieved and then the pages are iterated though in order to scrape the ids of the novels on each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages with novels: 1\n"
     ]
    }
   ],
   "source": [
    "def get_novel_list_num_pages(page):\n",
    "    \"\"\"\n",
    "    Get the maximum number of pages with novels.\n",
    "    This number is not contant since the number of novels on the website are increasing.\n",
    "    Following the current website layout each page have 25 novels.\n",
    "    \n",
    "    :param page: The web address to the novel list, presumably the first page but can be any.\n",
    "    :returns: An int representing the current number of pages of the novel lists.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    dig_pag = soup.find('div', attrs={'class':'digg_pagination'})\n",
    "    max_page = max([int(a.text) for a in dig_pag.find_all('a') if a.text.isdigit()])\n",
    "    return max_page\n",
    "\n",
    "# Get all novel ids from a single page\n",
    "def get_novel_ids(page):\n",
    "    \"\"\"\n",
    "    Gets all the novel ids from a page.\n",
    "    \n",
    "    :param page: One of the pages with novels.\n",
    "    :returns: A list with all novel ids for the novels on the page.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find('div', attrs={'class':'w-blog-content other'})\n",
    "    novels = table.find_all('div', attrs={'class': 'search_title'})\n",
    "    novel_ids = [novel.find('span', attrs={'class': 'rl_icons_en'}).get('id')[3:] for novel in novels]\n",
    "    novel_ids = [int(n) for n in novel_ids]\n",
    "    return novel_ids\n",
    "\n",
    "\n",
    "page = requests.get(novel_list_page + '1')\n",
    "\n",
    "# TOOD: For testing - only use 2 pages for now.\n",
    "novels_num_pages = 1\n",
    "#novels_max_pages = get_novel_list_num_pages(page)\n",
    "print(\"Pages with novels: \" + str(novels_num_pages))\n",
    "\n",
    "all_novel_ids = []\n",
    "for i in range(1, novels_num_pages+1):\n",
    "    page = requests.get(novel_list_page + str(i))\n",
    "    novel_ids = get_novel_ids(page)\n",
    "    all_novel_ids.extend(novel_ids)\n",
    "    time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(all_novel_ids, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(element, check=lambda e: e.string, parse=lambda e: e.string.strip()):\n",
    "    \"\"\"\n",
    "    Gets the value of a HTML element/node following the parse function. \n",
    "    This function is necessary since the novel pages are not always consistent with each other. \n",
    "    Also checks if the value is 'N/A' and returns None in that case.\n",
    "    \n",
    "    :param element: A HTML element/node.\n",
    "    :param check: A function to be applied on the element. \n",
    "                  Checks if the element object have a retrun value for the function or is it's None.\n",
    "    :param parse: A function to parse the element if it passes the check.\n",
    "    :returns: The value returned by running the parse function on the element.\n",
    "              None is returned if the element does not pass the check function or if the value is 'N/A'.\n",
    "    \"\"\"\n",
    "    if check(element) is None:\n",
    "        return None\n",
    "    pe = parse(element)\n",
    "    if ''.join(pe) == 'N/A':\n",
    "        return None\n",
    "    return pe\n",
    "\n",
    "              \n",
    "def get_value_str_txt(element, check_one=lambda e: e.string, parse_one=lambda e: e.string.strip(),\n",
    "                      check_two=lambda e: e.text, parse_two=lambda e: e.text.strip()):\n",
    "    \"\"\"\n",
    "    Used when it's unknown which function to apply on an element to obtain it's value.\n",
    "    For example, if .string or .text should be used.\n",
    "    The functions are applied in order, if the first one returns None then the second one is tried.\n",
    "    \n",
    "    :param element: A HTML element/node.\n",
    "    :param check_one: A function to be applied on the element.\n",
    "                      Checks if the element object have a retrun value for the function or is it's None.\n",
    "    :param parse_one: A function to parse the element if it passes the check.\n",
    "    :param check_two: A function to be applied on the element.\n",
    "                      Checks if the element object have a retrun value for the function or is it's None.\n",
    "    :param parse_two: A function to parse the element if it passes the check.\n",
    "    :returns: The value returned by running parse_one or parse_two on the element.\n",
    "    \"\"\"\n",
    "    res_one = get_value(element, check_one, parse_one)\n",
    "    res_two = get_value(element, check_two, parse_two)\n",
    "    return res_one or res_two\n",
    "              \n",
    "\n",
    "def empty(element):\n",
    "    \"\"\"\n",
    "    Checks if running .string on the element returns an empty string.\n",
    "    \n",
    "    :param element: A HTML element/node.\n",
    "    :returns: A boolean representing whether the element contains an empty string.\n",
    "    \"\"\"\n",
    "    return get_value(element) == \"\"\n",
    "\n",
    "\n",
    "def get_bool(string):\n",
    "    \"\"\"\n",
    "    Convinience function to convert a string to a boolean.\n",
    "    Handles Yes, yes, No and no.\n",
    "    \n",
    "    :param string: String to convert to boolean.\n",
    "    :retruns: The boolean representation of the string or None.\n",
    "    \"\"\"\n",
    "    if string is None:\n",
    "        return None\n",
    "    \n",
    "    if string.lower() == \"yes\":\n",
    "        return True\n",
    "    elif string.lower() == \"no\":\n",
    "        return False\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all general information of a specific novel.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    \n",
    "    gen_info = {}\n",
    "    gen_info['name'] = get_value(content.find('div', attrs={'class', 'seriestitlenu'}))\n",
    "    gen_info['assoc_names'] = get_value(content.find('div', attrs={'id': 'editassociated'}), \n",
    "                                        check=lambda e: e, parse=lambda e: list(e.stripped_strings))\n",
    "    gen_info['original_langauge'] = get_value(content.find('div', attrs={'id': 'showlang'}), \n",
    "                                          lambda e: e.a, \n",
    "                                          lambda e: e.text.strip().lower())\n",
    "    gen_info['authors'] = [author.text.lower()\n",
    "                for author in content\n",
    "                  .find('div', attrs={'id': 'showauthors'})\n",
    "                  .find_all('a')]\n",
    "    gen_info['genres'] = [genre.text.lower()\n",
    "                for genre in content\n",
    "                  .find('div', attrs={'id': 'seriesgenre'})\n",
    "                  .find_all('a', attrs={'class': 'genre'})]\n",
    "    gen_info['tags'] = [tag.text.lower()\n",
    "                for tag in content\n",
    "                  .find('div', attrs={'id': 'showtags'})\n",
    "                  .find_all('a')]\n",
    "    return gen_info\n",
    "\n",
    "\n",
    "def publisher_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all publisher information of a specific novel.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    pub_info = {}\n",
    "    pub_info['start_year'] = get_value(content.find('div', attrs={'id': 'edityear'}),)\n",
    "    pub_info['licensed'] = get_bool(get_value(content.find('div', attrs={'id': 'showlicensed'})))\n",
    "    pub_info['original_publisher'] = get_value(content.find('div', attrs={'id': 'showopublisher'}),\n",
    "                                               lambda e: e.a, \n",
    "                                               lambda e: e.a.string.strip().lower())\n",
    "    pub_info['english_publisher'] = get_value(content.find('div', attrs={'id': 'showepublisher'}),\n",
    "                                              lambda e: e.a, \n",
    "                                              lambda e: e.a.string.strip().lower())\n",
    "    return pub_info\n",
    "\n",
    "\n",
    "def chapter_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all chapter information of a specific novel. \n",
    "    Both latest released chapters and if the novel is complete.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    chap_info = {}\n",
    "    chapter_status = get_value_str_txt(content.find('div', attrs={'id': 'editstatus'}))\n",
    "    \n",
    "    if chapter_status is not None:\n",
    "        chap_info['complete_original'] = 'complete' in chapter_status.lower()\n",
    "        chapter_current = re.search('(\\d+)[ wnl]*(?=chap)', chapter_status.lower())\n",
    "        if chapter_current is not None:\n",
    "            chapter_current = chapter_current.group(1).strip() + \" chapters\"\n",
    "        else:    \n",
    "            # Check if volume\n",
    "            chapter_current = re.search('(\\d+)[ wnl]*(?=volu)', chapter_status.lower())\n",
    "            if chapter_current is not None:\n",
    "                chapter_current = chapter_current.group(1).strip() + \" volumes\"\n",
    "            else:\n",
    "                # Get the first number\n",
    "                chapter_current = re.search('(\\d+)', chapter_status.lower())\n",
    "                if chapter_current is not None:\n",
    "                    chapter_current = chapter_current.group(1).strip()        \n",
    "        \n",
    "        chap_info['chapters_original_current'] = chapter_current if chapter_current != \"\" else None \n",
    "    chap_info['complete_translated'] = get_bool(get_value(content.find('div', attrs={'id': 'showtranslated'})))\n",
    "    \n",
    "    table = content.find('table', attrs={'id': 'myTable'})\n",
    "    if table is not None:\n",
    "        release_table = table.find('tbody')\n",
    "        chap_info['chapter_latest_translated'] = release_table.find('tr').find_all('td')[2].a.string.strip()\n",
    "    return chap_info\n",
    "    \n",
    "    \n",
    "def release_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all release and activity information of a specific novel.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    rel_info = {}\n",
    "    release_freq = content.find('h5', attrs={'class': 'seriesother'}, string='Release Frequency').next_sibling\n",
    "    activity = content.find_all('span', attrs={'class': 'userrate rank'})\n",
    "    \n",
    "    if not empty(release_freq):\n",
    "        rel_info['release_freq'] = float(re.search('\\d+\\.?\\d*', release_freq).group(0))\n",
    "        \n",
    "    rel_info['activity_week_rank'] = int(activity[0].string[1:])\n",
    "    rel_info['activity_month_rank'] = int(activity[1].string[1:])\n",
    "    rel_info['activity_all_time_rank'] = int(activity[2].string[1:])\n",
    "    return rel_info\n",
    "    \n",
    "\n",
    "def community_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all community information of a specific novels.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    comm_info = {}\n",
    "    activity = content.find_all('span', attrs={'class': 'userrate rank'})\n",
    "    comm_info['on_reading_lists'] = int(content.find('b', attrs={'class': 'rlist'}).string)\n",
    "    comm_info['reading_list_month_rank'] = int(activity[3].string[1:])\n",
    "    comm_info['reading_list_all_time_rank'] = int(activity[4].string[1:])\n",
    "    \n",
    "    # rating\n",
    "    rating_text = content.find('span', attrs={'class': 'uvotes'}).text.split(' ')\n",
    "    comm_info['rating'] = float(rating_text[0][1:])\n",
    "    comm_info['rating_votes'] = int(rating_text[3])\n",
    "    return comm_info\n",
    "    \n",
    "    \n",
    "def relation_info(content):\n",
    "    \"\"\"\n",
    "    Scrapes all relational information of a specific novel.\n",
    "    \n",
    "    :param content: The content page of a novel.\n",
    "    :returns: A dictionary with scraped and cleaned information.\n",
    "    \"\"\"\n",
    "    rel_info = {}\n",
    "    two_third_content = content.find('div', attrs={'class': 'two-thirds'})\n",
    "    wpb_wrapper = two_third_content.find('div', attrs={'class': 'wpb_wrapper'})\n",
    "    \n",
    "    rel_info['related_series_ids'] = []\n",
    "    rel_info['recommended_series_ids'] = []\n",
    "    rel_info['recommendation_list_ids'] = []\n",
    "    for series in wpb_wrapper.findChildren('a', attrs={'class': 'genre'}, recursive=False):\n",
    "        if series.has_attr('title'):\n",
    "            rel_info['recommended_series_ids'].append(series.get('id')[3:])\n",
    "        else:\n",
    "            rel_info['related_series_ids'].append(series.get('id')[3:])\n",
    "            \n",
    "    rec_lists = wpb_wrapper.find('ol', attrs={'class': 'ulc_sp'})\n",
    "    if rec_lists:\n",
    "        rel_info['recommendation_list_ids'] = [int(a['href'].split('/')[-2]) \n",
    "                                               for a in rec_lists.findChildren('a')]\n",
    "    return rel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2765\n",
      "9120\n",
      "19742\n",
      "24925\n",
      "15828\n",
      "15448\n",
      "27671\n",
      "22733\n",
      "27989\n",
      "26622\n",
      "27806\n",
      "14562\n",
      "14419\n",
      "6363\n",
      "18679\n",
      "15752\n",
      "4332\n",
      "26893\n",
      "9513\n",
      "20793\n",
      "24894\n",
      "26676\n",
      "20767\n",
      "24402\n",
      "23023\n",
      "<bound method NDFrame.head of        id                                               name  \\\n",
      "0    2765      A Record of a Mortal’s Journey to Immortality   \n",
      "1    9120                               A Round Trip To Love   \n",
      "2   19742    Akuyaku Reijo Nanode Rasubosu o Katte Mimashita   \n",
      "3   24925  Although It’s the Weakest an Unprofitable Occu...   \n",
      "4   15828              Arafoo Kenja no Isekai Seikatsu Nikki   \n",
      "5   15448               As the Minor Gay Rival in Het Novels   \n",
      "6   27671  Clearing an Isekai with the Zero-Believers God...   \n",
      "7   22733                         Co-renting Immortal Doctor   \n",
      "8   27989                     Comeback of the Abandoned Wife   \n",
      "9   26622                                  Control The World   \n",
      "10  27806                        Demoness’s Art of Vengeance   \n",
      "11  14562          Divine Doctor: Daughter of the First Wife   \n",
      "12  14419                                      Ecstas Online   \n",
      "13   6363                               Emperor’s Domination   \n",
      "14  18679  Evil Emperor’s Poisonous Consort: Divine Docto...   \n",
      "15  15752                               Extraordinary Genius   \n",
      "16   4332                                  Heaven’s Devourer   \n",
      "17  26893             I Am In The Middle Of Being Hypnotised   \n",
      "18   9513                           I Heard You Are an Alien   \n",
      "19  20793                I Just Want to Be in a Relationship   \n",
      "20  24894  I Woke Up Piloting the Strongest Starship, so ...   \n",
      "21  26676                         Ihoujin, Dungeon ni Moguru   \n",
      "22  20767                         Immemorial Sword Venerable   \n",
      "23  24402  In which the System Torments the Protagonists:...   \n",
      "24  23023                   Indulgent Husband and Sweet Wife   \n",
      "\n",
      "                                          assoc_names original_langauge  \\\n",
      "0   [Fan Ren Xiu Xian Chuan, Phàm Nhân Tu Tiên, RM...           chinese   \n",
      "1                                             [双程之归途]           chinese   \n",
      "2   [Villainous Daughter Aims for the Last Boss, 作...          japanese   \n",
      "3   [不遇職『鍛冶師』だけど最強です　～気づけば何でも作れるようになっていた男ののんびりスローラ...          japanese   \n",
      "4   [The Diary Of A Sage Around 40 Living In Anoth...          japanese   \n",
      "5        [BG wén lǐ de jī lǎo nán pèi, BG文里的基佬男配[快穿]]           chinese   \n",
      "6   [Shinja Zero no Megamisama to Kajimeru Isekai ...          japanese   \n",
      "7                                              [合租医仙]           chinese   \n",
      "8                                              [废妻重生]           chinese   \n",
      "9                                              [执掌山海]           chinese   \n",
      "10                                           [魔女打脸攻略]           chinese   \n",
      "11  [Shen Yi Di Nu, The Prodigy Daughter Of The Me...           chinese   \n",
      "12                                      [エクスタス・オンライン]          japanese   \n",
      "13                             [Di Ba, ED, Đế Bá, 帝霸]           chinese   \n",
      "14                            [EEPC:DDYM, 邪帝毒妃：神医大小姐]           chinese   \n",
      "15                             [Chāo pǐn qícái, 超品奇才]           chinese   \n",
      "16         [Swallowing the Heavens, Tūn Tiān Jì, 吞天记]           chinese   \n",
      "17                                       [私は今も催眠の途中。]          japanese   \n",
      "18                                  [聽說你是外星人／看來你是外星人]           chinese   \n",
      "19                                          [我就想谈个恋爱]           chinese   \n",
      "20  [Mezametara Saikyou Soubi to Uchuusen Mochidat...          japanese   \n",
      "21  [Kotokunibito Dungeon ni Moguru, The Foreigner...          japanese   \n",
      "22                                             [太古剑尊]           chinese   \n",
      "23  [Ta Tuổi Còn Trẻ Tưởng Thủ Sống Quả [ Xuyên Th...           chinese   \n",
      "24                                             [宠昏甜妻]           chinese   \n",
      "\n",
      "                                              authors  \\\n",
      "0                                       [wang yu, 忘语]   \n",
      "1                                       [lan lin, 藍淋]   \n",
      "2                              [nagase sarasa, 永瀬さらさ]   \n",
      "3                                [ryuta kijima, 木嶋隆太]   \n",
      "4                                 [yasukiyo kotobuki]   \n",
      "5                                       [xixili, 夕夕里]   \n",
      "6                                [oosaki isle, 大崎アイル]   \n",
      "7                        [a box of white paper, 白纸一箱]   \n",
      "8                                  [jin yuanbao, 金元宝]   \n",
      "9                              [hui fei de zhu, 会飞的猪]   \n",
      "10                             [meditation rock, 冥想石]   \n",
      "11                                 [mao shi liu, 猫十六]   \n",
      "12                            [kuji masamune, 久慈マサムネ]   \n",
      "13                          [yan bi xiao sheng, 厌笔萧生]   \n",
      "14  [sounds of snow in the night, ye yin ru xue, 夜...   \n",
      "15                                     [qióng sì, 穷四]   \n",
      "16                                              [风青阳]   \n",
      "17                                      [signs, サインズ]   \n",
      "18                       [three thousand glass, 三千琉璃]   \n",
      "19                                    [lian shuo, 连朔]   \n",
      "20                                       [lute, リュート]   \n",
      "21                              [asami hinagi, 麻美ヒナギ]   \n",
      "22                                             [青石细语]   \n",
      "23                                             [公子闻筝]   \n",
      "24                             [murong xiaodai, 慕容小呆]   \n",
      "\n",
      "                                               genres  \\\n",
      "0                [action, adventure, mature, xianxia]   \n",
      "1               [adult, drama, mature, tragedy, yaoi]   \n",
      "2                          [fantasy, romance, shoujo]   \n",
      "3   [adventure, fantasy, harem, mystery, romance, ...   \n",
      "4   [adventure, fantasy, harem, seinen, slice of l...   \n",
      "5                            [fantasy, romance, yaoi]   \n",
      "6   [action, adventure, comedy, fantasy, harem, my...   \n",
      "7   [action, ecchi, fantasy, harem, martial arts, ...   \n",
      "8                   [comedy, romance, xuanhuan, yaoi]   \n",
      "9                                 [xianxia, xuanhuan]   \n",
      "10           [action, harem, josei, romance, xianxia]   \n",
      "11              [drama, josei, martial arts, romance]   \n",
      "12  [action, adult, adventure, comedy, drama, ecch...   \n",
      "13  [action, adventure, fantasy, harem, martial ar...   \n",
      "14  [action, adventure, fantasy, martial arts, sho...   \n",
      "15  [harem, mature, romance, school life, seinen, ...   \n",
      "16  [action, adventure, fantasy, harem, martial ar...   \n",
      "17                                    [adult, seinen]   \n",
      "18                 [comedy, fantasy, romance, sci-fi]   \n",
      "19      [comedy, drama, romance, slice of life, yaoi]   \n",
      "20  [action, adventure, ecchi, fantasy, harem, mec...   \n",
      "21                [action, adventure, fantasy, harem]   \n",
      "22      [action, martial arts, supernatural, xianxia]   \n",
      "23            [comedy, drama, josei, romance, shoujo]   \n",
      "24            [comedy, josei, romance, slice of life]   \n",
      "\n",
      "                                                 tags start_year licensed  \\\n",
      "0   [alchemy, artifacts, average-looking protagoni...       2008     True   \n",
      "1   [adapted to movie, cold protagonist, incest, l...       None     None   \n",
      "2   [adapted to manga, aristocracy, beautiful fema...       2017    False   \n",
      "3   [adventurers, artifact crafting, beast compani...       2019     None   \n",
      "4   [adapted to manga, cheats, game elements, gole...       2016    False   \n",
      "5   [devoted love interests, episodic, love intere...  2016-2017     None   \n",
      "6   [adventurers, cheats, clever protagonist, deat...       2018     None   \n",
      "7   [cultivation, doctors, male protagonist, moder...       2015    False   \n",
      "8                                                  []       None     None   \n",
      "9   [adventurers, male protagonist, transplanted m...       None    False   \n",
      "10  [arranged marriage, arrogant characters, beast...       None     True   \n",
      "11  [adapted to manhua, beautiful female lead, bet...       2015    False   \n",
      "12  [adapted to drama cd, adapted to manga, antihe...       2016     None   \n",
      "13  [alchemy, appearance different from actual age...       2014    False   \n",
      "14  [alchemy, assassins, beast companions, beautif...       2016     None   \n",
      "15  [arrogant characters, business management, bus...       2015    False   \n",
      "16  [betrayal, body tempering, buddhism, cultivati...       2015     True   \n",
      "17  [exhibitionism, female protagonist, hypnotism,...       2016    False   \n",
      "18  [alchemy, aliens, cohabitation, cultivation, c...       2014     None   \n",
      "19  [acting, calm protagonist, celebrities, charac...       2017     None   \n",
      "20  [adapted to manga, artificial intelligence, be...       2019    False   \n",
      "21  [adapted to manga, adventurers, alternate worl...       2016    False   \n",
      "22   [male protagonist, transported to another world]       None     None   \n",
      "23  [acting, arranged marriage, beautiful female l...       2019     None   \n",
      "24  [female protagonist, modern day, older love in...       None    False   \n",
      "\n",
      "        original_publisher english_publisher complete_original  \\\n",
      "0                   qidian        wuxiaworld              True   \n",
      "1                     None              None               NaN   \n",
      "2                 kadokawa              None              True   \n",
      "3                  syosetu              None             False   \n",
      "4            media factory              None             False   \n",
      "5                    jjwxc              None              True   \n",
      "6                  syosetu              None             False   \n",
      "7                  zhulang              None             False   \n",
      "8                  lc read              None               NaN   \n",
      "9                    梧桐中文网              None               NaN   \n",
      "10                     17k        wuxiaworld              True   \n",
      "11                   motie              None              True   \n",
      "12                kadokawa              None              True   \n",
      "13                  qidian        wuxiaworld             False   \n",
      "14                  qidian              None             False   \n",
      "15                  qidian              None              True   \n",
      "16                     17k        wuxiaworld              True   \n",
      "17                 syosetu              None              True   \n",
      "18   ever glory publishing              None              True   \n",
      "19                   jjwxc              None              True   \n",
      "20                kadokawa              None             False   \n",
      "21  kadokawa dragon novels              None             False   \n",
      "22                   motie              None             False   \n",
      "23                   jjwxc              None              True   \n",
      "24                zongheng              None              True   \n",
      "\n",
      "   chapters_original_current  complete_translated chapter_latest_translated  \\\n",
      "0              2446 chapters                False                     c1306   \n",
      "1                        NaN                False                     v1c18   \n",
      "2               284 chapters                False           v2 side story 1   \n",
      "3                70 chapters                False                       c57   \n",
      "4               180 chapters                False                       c28   \n",
      "5                        106                False                  c6 part2   \n",
      "6               200 chapters                False                       c21   \n",
      "7              5815 chapters                False                       c68   \n",
      "8                        NaN                False                        c6   \n",
      "9                        NaN                False                       c65   \n",
      "10              401 chapters                False                       c48   \n",
      "11             1252 chapters                False                     c1020   \n",
      "12                 8 volumes                False                      v2c3   \n",
      "13             3924 chapters                False                     c2775   \n",
      "14             3526 chapters                False                      c829   \n",
      "15             2090 chapters                False                      c830   \n",
      "16             1828 chapters                False                      c587   \n",
      "17               10 chapters                False                        c7   \n",
      "18              180 chapters                False                       c80   \n",
      "19               96 chapters                False                      c199   \n",
      "20              141 chapters                False                       c35   \n",
      "21              417 chapters                False                       c11   \n",
      "22             3847 chapters                False                       c55   \n",
      "23              106 chapters                False                       c53   \n",
      "24                      None                False                       c33   \n",
      "\n",
      "    release_freq  activity_week_rank  activity_month_rank  \\\n",
      "0            0.5                  64                   65   \n",
      "1           79.5                1624                 1331   \n",
      "2            1.7                1254                  447   \n",
      "3            3.3                 289                  238   \n",
      "4            4.3                 568                  236   \n",
      "5            8.6                 529                  363   \n",
      "6            1.1                  58                  112   \n",
      "7            1.1                2431                 2000   \n",
      "8            1.0                2000                  526   \n",
      "9            1.1                2833                 2000   \n",
      "10           0.5                 100                  194   \n",
      "11           2.5                 315                  329   \n",
      "12          53.2                1052                 1130   \n",
      "13           0.5                   4                    4   \n",
      "14           3.7                1110                 1192   \n",
      "15           0.9                 102                   72   \n",
      "16           0.5                 134                  156   \n",
      "17           7.0                1369                   52   \n",
      "18           0.9                 682                  701   \n",
      "19           1.1                  43                   24   \n",
      "20           4.2                 239                  106   \n",
      "21           3.7                 713                  667   \n",
      "22           7.2                2833                 3665   \n",
      "23           1.9                  71                  168   \n",
      "24           6.6                2636                 2000   \n",
      "\n",
      "    activity_all_time_rank  on_reading_lists  reading_list_month_rank  \\\n",
      "0                       85              8732                       58   \n",
      "1                     3473               639                     3613   \n",
      "2                      608              7584                      775   \n",
      "3                     1221              1494                      261   \n",
      "4                     1158              4587                      253   \n",
      "5                      685              5112                      583   \n",
      "6                     2319              1101                      156   \n",
      "7                     4930               242                     4599   \n",
      "8                     5117               250                     2138   \n",
      "9                     5460               102                     5226   \n",
      "10                    2758               610                      262   \n",
      "11                      72              7582                      421   \n",
      "12                    1528              3648                     1172   \n",
      "13                       2             16808                        5   \n",
      "14                     693              2472                     1255   \n",
      "15                     248              3298                      117   \n",
      "16                     647              3104                      140   \n",
      "17                    4507               278                     2054   \n",
      "18                    2560               808                      738   \n",
      "19                     423              4460                       51   \n",
      "20                    1369              2333                      102   \n",
      "21                    3345               818                      775   \n",
      "22                    5725               128                     5165   \n",
      "23                    1103              3288                       75   \n",
      "24                    4235               439                     3530   \n",
      "\n",
      "    reading_list_all_time_rank  rating  rating_votes   related_series_ids  \\\n",
      "0                          189     4.0           636                   []   \n",
      "1                         3575     3.5            28  [1411, 1611, 17765]   \n",
      "2                          264     4.5           201                   []   \n",
      "3                         2242     3.2            52                   []   \n",
      "4                          660     4.1           128                   []   \n",
      "5                          544     4.4           224                   []   \n",
      "6                         2713     4.3            51                   []   \n",
      "7                         4923     2.1            13                   []   \n",
      "8                         4888     3.6            17                   []   \n",
      "9                         5768     1.8             6                   []   \n",
      "10                        3650     3.8            19                   []   \n",
      "11                         264     4.1           379                   []   \n",
      "12                         894     3.9           128                   []   \n",
      "13                          24     3.9          1792                   []   \n",
      "14                        1457     3.5            70                   []   \n",
      "15                        1008     3.8           228                   []   \n",
      "16                        1119     3.8           189                   []   \n",
      "17                        4755     2.9            17                   []   \n",
      "18                        3196     4.1            66                   []   \n",
      "19                         688     4.5           251                   []   \n",
      "20                        1551     3.9            69                   []   \n",
      "21                        3184     4.1            34                   []   \n",
      "22                        5602     3.8             6                   []   \n",
      "23                        1012     4.5            74              [24019]   \n",
      "24                        4128     3.2            18                   []   \n",
      "\n",
      "                        recommended_series_ids         recommendation_list_ids  \n",
      "0             [15, 180, 181, 5844, 364, 21237]  [6333, 5665, 5296, 4650, 4633]  \n",
      "1         [11330, 540, 10025, 538, 9316, 8552]                              []  \n",
      "2    [5280, 15652, 21030, 17274, 19924, 18891]  [6293, 6251, 6129, 6099, 6077]  \n",
      "3   [23147, 22904, 22762, 23653, 15252, 10681]               [2708, 1984, 482]  \n",
      "4                                [4510, 17431]     [6156, 2923, 238, 183, 135]  \n",
      "5   [16033, 12209, 15222, 15508, 15030, 11330]  [6419, 6418, 6172, 5852, 5427]  \n",
      "6      [25724, 4919, 506, 15592, 26204, 16222]                           [187]  \n",
      "7                          [16412, 11734, 513]                          [3261]  \n",
      "8                                           []                              []  \n",
      "9                                           []                              []  \n",
      "10                        [27812, 18935, 9010]                           [482]  \n",
      "11      [21980, 7759, 9010, 5154, 8499, 14233]  [6375, 6209, 6023, 5897, 5845]  \n",
      "12                                      [4894]                    [2562, 1951]  \n",
      "13            [3952, 2039, 14, 791, 4214, 631]  [6348, 6333, 6266, 6185, 6163]  \n",
      "14      [17397, 18935, 7934, 5504, 6491, 7983]  [6337, 6209, 6023, 4293, 3829]  \n",
      "15    [6001, 12625, 8033, 12698, 15181, 15196]  [5936, 4944, 4522, 3261, 3218]  \n",
      "16                                          []                          [4077]  \n",
      "17                                          []                              []  \n",
      "18                                          []                    [5275, 4578]  \n",
      "19  [12274, 17248, 20811, 14032, 19987, 12993]  [6425, 6402, 6172, 6110, 6080]  \n",
      "20          [23069, 6386, 23903, 20597, 18394]     [4837, 3349, 942, 482, 168]  \n",
      "21                                      [1381]               [6001, 5402, 520]  \n",
      "22                                          []                              []  \n",
      "23  [25720, 24019, 24468, 23635, 24968, 24696]  [6177, 6052, 5958, 5810, 5718]  \n",
      "24                                          []                          [4455]  >\n"
     ]
    }
   ],
   "source": [
    "def parse_novel_page(novel_id):\n",
    "    \"\"\"\n",
    "    Parses and scrapes information from a single novel page.\n",
    "    \n",
    "    :param novel_id: The id number of the novel.\n",
    "    :returns: A pandas series with all scraped and cleaned information about the novel.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = requests.get(novel_page + str(novel_id))    \n",
    "    soup = BeautifulSoup(page.content, 'html5lib')\n",
    "    content = soup.find('div', attrs={'class': 'w-blog-content'})\n",
    "    if content is None:\n",
    "        return pd.Series() \n",
    "    \n",
    "    #print(novel_id)\n",
    "    \n",
    "    data = {'id': novel_id}\n",
    "    data.update(general_info(content))\n",
    "    data.update(publisher_info(content))\n",
    "    data.update(chapter_info(content))\n",
    "    data.update(release_info(content))\n",
    "    data.update(community_info(content))\n",
    "    data.update(relation_info(content))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    return pd.Series(data)\n",
    "\n",
    "df = df['id'].apply(lambda novel_id: parse_novel_page(novel_id))\n",
    "#df = df.set_index('id')\n",
    "print(df.head)\n",
    "#df.to_csv('novels.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
