{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapes the novelupdates webpage, http://www.novelupdates.com/\n",
    "for novel information and cleans it.\n",
    "Finally saves the dataset as a csv file.\n",
    "\n",
    "Didn't find any easy way to get all the novel ids, hence, the novels listing is first used to get all ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "novel_list_page = \"http://www.novelupdates.com/novelslisting/?st=1&pg=\"\n",
    "novel_page = \"http://www.novelupdates.com/?p=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum number of novel pages from the listings\n",
    "\n",
    "def get_novel_list_max_pages(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    dig_pag = soup.find('div', attrs={'class':'digg_pagination'})\n",
    "    page_links = dig_pag.find_all('a')\n",
    "    last_page_link = str(page_links[2]) # The last page is the 3rd\n",
    "    num = re.search('pg=\\d+', last_page_link).group()[3:]\n",
    "    return int(num)\n",
    "\n",
    "page = requests.get(novel_list_page + '1')\n",
    "novels_max_pages = get_novel_list_max_pages(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_max_pages = 1\n",
    "\n",
    "# Get all novel ids from the novels listing\n",
    "def get_novel_ids(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find('table', attrs={'id':'myTable'})\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    \n",
    "    novel_ids = []\n",
    "    for row in rows:\n",
    "        col = row.find_all('td')[-1]\n",
    "        novel_id = col.a['id'][3:]\n",
    "        novel_ids.append(novel_id)\n",
    "    return novel_ids\n",
    "\n",
    "all_novel_ids = []\n",
    "for i in range(1,novels_max_pages+1):\n",
    "    page = requests.get(novel_list_page + str(i))\n",
    "    novel_ids = get_novel_ids(page)\n",
    "    all_novel_ids.extend(novel_ids)\n",
    "    time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(all_novel_ids, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Adventure', 'Comedy', 'Drama', 'Fantasy', 'Martial Arts', 'Romance', 'Xianxia']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_novel_page(id):\n",
    "#    page = requests.get(novel_page + str(id))\n",
    "    page = requests.get(id) # TEMP\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    wrapper = soup.find('div', attrs={'class': 'wpb_wrapper'})\n",
    "    \n",
    "    #tags =\n",
    "    \n",
    "    genres = [genre.text\n",
    "              for genre in wrapper\n",
    "                .find('div', attrs={'id': 'seriesgenre'})\n",
    "                .find_all('a', attrs={'class': 'genre'})]\n",
    "\n",
    "    \n",
    "    #rating =\n",
    "    #rating_votes =\n",
    "    #langauge =\n",
    "    #author = \n",
    "    #start_year = \n",
    "    #volumes_total =\n",
    "    #chapters_total =\n",
    "    #chapters_translated =\n",
    "    #complete\n",
    "    #complete_translated =\n",
    "    #licensed = \n",
    "    #original_publisher =\n",
    "    #english_publisher =\n",
    "    #release_freq = \n",
    "    #activity_week_rank =\n",
    "    #activity_month_rank =\n",
    "    #activity_all_time_rank =\n",
    "    #on_reading_lists =\n",
    "    #reading_list_month_rank =\n",
    "    #reading_list_all_time_rank = \n",
    "    #assoc_names = \n",
    "    #related_series_ids =\n",
    "    #recommended_series_ids =\n",
    "    \n",
    "    \n",
    "    # return these as a map (name -> result)\n",
    "    # add these as new columns to the df\n",
    "    time.sleep(1)\n",
    "    return 3\n",
    "\n",
    "#https://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "parse_novel_page('http://www.novelupdates.com/series/i-shall-seal-the-heavens/')\n",
    "\n",
    "# div id=\"seriesgenre\" / class=\"genre\"\n",
    "# <a class=\"genre\" gid=\"8\" href=\"http://www.novelupdates.com/genre/action/\" title=\"A work typically depicting fighting, violence, chaos, and fast paced motion.\">Action</a>\n",
    "\n",
    "# h5 class=seriesother / class=\"uvotes\"\n",
    "# <span class=\"uvotes\">(4.4 / 5.0, 2481 votes)</span>\n",
    "    \n",
    "#df['test'] = df.apply(lambda x: parse_novel_page(x['Id']), axis=1)\n",
    "#df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
